\chapter{CONSTRUÇÃO DO MODELO COMPUTACIONAL}

O presente capítulo descreve, de forma aplicada e detalhada, o processo de implementação do modelo computacional desenvolvido para identificação do \textit{Ideal Customer Profile} (ICP) no setor de benefícios corporativos. A construção foi realizada em ambiente \textit{Google Colab}, utilizando a linguagem Python (versão 3.10) e bibliotecas como \texttt{pandas}, \texttt{scikit-learn}, \texttt{numpy} e \texttt{seaborn}. O pipeline proposto combina etapas de pré-processamento, detecção de \textit{outliers} e ranqueamento via medidas de similaridade (\textit{Distance-Based Scoring}), compondo um fluxo modular e reprodutível.

\section{VISÃO GERAL DO PIPELINE}

O pipeline implementado foi estruturado em funções independentes, permitindo a aplicação em diferentes bases de empresas. A Figura~\ref{fig:fluxo_pipeline} ilustra as principais etapas:
\begin{enumerate}
    \item \textbf{Pré-processamento dos dados firmográficos};
    \item \textbf{Detecção de outliers} com o algoritmo \textit{Isolation Forest};
    \item \textbf{Cálculo de similaridade} por meio de duas métricas complementares (Distância ao centróide e Distância média aos $k$ vizinhos mais próximos);
    \item \textbf{Ranking final híbrido}, ponderando as métricas de similaridade.
\end{enumerate}

A estrutura modular do código garante escalabilidade e reuso, mantendo o pipeline íntegro e parametrizável. Todas as etapas foram executadas sobre a base de 351 empresas coletadas via \textit{scraping} e tratadas previamente.

\section{PRÉ-PROCESSAMENTO DOS DADOS}

A etapa de pré-processamento teve como objetivo adaptar a base de dados a um formato numérico e padronizado, compatível com os algoritmos de aprendizado de máquina utilizados na modelagem do ICP.

\subsection{Padronização e limpeza inicial}

O conjunto de dados foi importado diretamente do Google Drive, de arquivo .csv para cada uma das bases de dados das 5 empresas que a compõe, e as colunas foram renomeadas para o padrão \textit{snake\_case} com remoção de acentos e espaços. Foram eliminadas variáveis irrelevantes como \texttt{CNPJ}, URLs, descrições textuais e intervalos categóricos de capital e funcionários. Estas foram as variáveis efetivamente empregadas:

\begin{itemize}
    \item \textbf{Numéricas:} \texttt{capital\_social}, \texttt{funcionários};
    \item \textbf{Categóricas:} \texttt{segmento}, \texttt{estado}.
\end{itemize}

\subsection{Normalização da variável de localização}

A coluna \texttt{localização}, originalmente composta por cadeias heterogêneas (por exemplo, ``Curitiba, Paraná'' ou ``São Paulo, SP''), foi tratada pela função \texttt{parse\_localizacao()}, que identifica e padroniza o estado (UF) de cada empresa. Casos internacionais permaneceram sem UF definida. Apenas o campo \texttt{estado} foi mantido como variável categórica final.

\subsection{Tratamento numérico e vetorização}

Os valores de capital social e número de funcionários foram convertidos para tipo numérico após a remoção de separadores e símbolos. Em seguida, utilizou-se um \texttt{ColumnTransformer} contendo dois fluxos principais:
\begin{itemize}
    \item \textbf{Pipeline numérico:} \texttt{SimpleImputer(strategy='median')} e \texttt{StandardScaler()};
    \item \textbf{Pipeline categórico:} \texttt{SimpleImputer(strategy='most\_frequent')} e \texttt{OneHotEncoder(sparse=False)}.
\end{itemize}

\section{OCC: DETECÇÃO DE OUTLIERS}

Após o pré-processamento, foi aplicada a etapa de detecção de empresas com padrões firmográficos atípicos, utilizando o algoritmo \textit{Isolation Forest}. O modelo foi implementado diretamente sobre a matriz vetorizada \texttt{X\_processed}, com parâmetros definidos para 5\% de contaminação e \texttt{random\_state=42}, garantindo consistência entre execuções.

No código, o modelo foi ajustado (\texttt{fit}) e posteriormente utilizado para gerar dois vetores: \texttt{iso\_labels}, contendo a classificação binária de cada empresa (\texttt{1} para inlier e \texttt{-1} para outlier), e \texttt{iso\_scores}, com o grau de normalidade calculado pelo modelo. Os valores foram invertidos para que maiores scores representassem maior aderência ao perfil típico da amostra.

A filtragem foi implementada com uma máscara booleana, preservando apenas as instâncias rotuladas como \textit{inliers}, originando os conjuntos \texttt{X\_inliers} e \texttt{df\_inliers}. O procedimento resultou na exclusão de aproximadamente 5\% das empresas originais, removendo casos extremos de capital ou porte, e preparando a base para a etapa de cálculo de similaridade.

Essa decisão de design — usar o \textit{Isolation Forest} como filtro inicial — teve caráter prático: simplifica a eliminação de ruído sem exigir hiperparâmetros complexos, garantindo estabilidade e consistência antes da etapa de ranqueamento.

\section{CÁLCULO DE SIMILARIDADE (DBS)}

Com a base final de empresas consideradas \textit{inliers}, foi executada a etapa de cálculo de similaridade, que atribui a cada empresa um valor contínuo de aderência ao perfil ICP. Essa etapa foi inteiramente implementada no Colab e aplicada apenas às observações não classificadas como outliers pelo \textit{Isolation Forest}.

O cálculo foi conduzido em duas partes, ambas baseadas em medidas de distância no espaço vetorial padronizado. Primeiramente, foi criada uma máscara booleana de \textit{inliers} (\texttt{iso\_forest\_predictions == 1}) para garantir que apenas as empresas consistentes participassem do processo. Em seguida, dois vetores de pontuação foram inicializados com valores nulos (\texttt{NaN}) e preenchidos apenas para as posições válidas.

\subsection{Distância ao centróide}

O primeiro cálculo mediu a distância de cada empresa ao centróide do conjunto de \textit{inliers}, obtido pela média de todas as variáveis numéricas e categóricas codificadas. A partir dessas distâncias, foi utilizada uma normalização local com \texttt{MinMaxScaler} e invertido o sinal dos resultados, de modo que empresas mais próximas ao centróide recebessem valores mais altos de similaridade. Essa operação gerou o vetor \texttt{dbs\_centroid\_scores}, que representa a aderência global ao perfil médio do ICP. O código também imprimiu a média desses scores e gerou um histograma de distribuição para inspeção visual da concentração dos resultados.

\subsection{Distância média aos vizinhos mais próximos}

Na segunda parte, foi aplicada a métrica de densidade local, que calcula a distância média de cada empresa a seus dez vizinhos mais próximos no espaço vetorial. Foi utilizado o método \texttt{NearestNeighbors} com $k=10$, e para cada ponto foi calculada a média das distâncias, desconsiderando a auto-referência. Assim como na etapa anterior, os valores foram normalizados para o intervalo [0,1] e invertidos, produzindo o vetor \texttt{dbs\_knn\_scores}. 

A média dos scores normalizados também foi registrada e visualizada por meio de um histograma, permitindo identificar o comportamento da densidade entre os \textit{inliers}. Empresas com pontuação elevada nessa métrica estão em regiões do espaço com maior concentração de perfis semelhantes.

\subsection{Síntese da etapa}

Ao final, o procedimento resultou em dois vetores de scores — um baseado na centralidade (centróide) e outro na densidade local (k-NN) —, ambos associados apenas às empresas \textit{inliers}. Essa estrutura forneceu as métricas quantitativas que alimentam o ranking final híbrido apresentado na próxima seção.

\section{RANKING FINAL HÍBRIDO}

Com as métricas de similaridade calculadas, a etapa seguinte consistiu em consolidar os resultados em um único indicador contínuo, representando o grau de aderência de cada empresa ao perfil ICP. O ranqueamento final foi estruturado de forma híbrida, utilizando as duas métricas de \textit{Distance-Based Scoring} (centróide e k-NN), ponderadas segundo sua relevância empírica observada nos testes.

\subsection{Combinação ponderada dos scores}

No código, foi criado um novo \texttt{DataFrame} chamado \texttt{scores\_df}, contendo as pontuações de cada métrica para todas as empresas. As colunas principais incluem os vetores \texttt{dbs\_centroid\_scores} e \texttt{dbs\_knn\_scores}, calculados exclusivamente para as instâncias classificadas como \textit{inliers}. 

O cálculo do score final foi feito de forma ponderada, atribuindo peso de 0.8 à métrica de centróide e 0.2 à métrica de k-NN, conforme a expressão:

\[
\text{score\_final}_i = 0.8 \times \text{dbs\_centroid\_score}_i + 0.2 \times \text{dbs\_knn\_score}_i
\]

Essa proporção foi definida após experimentação empírica, considerando que a distância ao centróide reflete de maneira mais estável o alinhamento global ao perfil médio, enquanto o componente k-NN adiciona sensibilidade à densidade local de perfis semelhantes.

\subsection{Tratamento de outliers e política de preenchimento}

Empresas marcadas como \textit{outliers} pelo \textit{Isolation Forest} não participam da média ponderada. A função de ranqueamento implementa uma política de exclusão configurável (\texttt{outlier\_policy}), que define se os casos removidos devem receber valor nulo (\texttt{NaN}) ou zero. Por padrão, foi utilizada a opção \texttt{"nan"}, excluindo-os da ordenação final.

\subsection{Geração do ranking}

Após a combinação dos scores, os resultados foram normalizados e ordenados de forma decrescente. O notebook exibe automaticamente o \textit{Top 10} das empresas com maior pontuação média, destacando aquelas mais próximas ao perfil ideal modelado. Esse resultado corresponde ao conjunto de clientes com maior similaridade estatística ao ICP definido, funcionando como uma priorização quantitativa para prospecção comercial.

\subsection{Resumo da etapa}

A abordagem híbrida adotada — ponderando centralidade global e densidade local — produziu um ranking contínuo e interpretável. Essa configuração privilegia empresas que não apenas se aproximam do perfil médio, mas também estão situadas em regiões de alta concentração de perfis semelhantes, equilibrando robustez e precisão na definição do ICP.